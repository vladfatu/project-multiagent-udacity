{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c01249b1",
   "metadata": {},
   "source": [
    "# Collaboration and Competition\n",
    "\n",
    "---\n",
    "\n",
    "This notebook is my solution to the third project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893).\n",
    "\n",
    "### 1. Import the needed packages and start the Tennis Unity Environment\n",
    "\n",
    "Make sure you follow the setup described in the README of this repository before running the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a337bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "from unityagents import UnityEnvironment\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from multi_ddpg_agent import MultiAgentController\n",
    "\n",
    "env = UnityEnvironment(file_name=\"Tennis.app\") \n",
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4e8ab6",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, two agents control rackets to bounce a ball over a net. If an agent hits the ball over the net, it receives a reward of +0.1.  If an agent lets a ball hit the ground or hits the ball out of bounds, it receives a reward of -0.01.  Thus, the goal of each agent is to keep the ball in play.\n",
    "\n",
    "The observation space consists of 8 variables corresponding to the position and velocity of the ball and racket. Two continuous actions are available, corresponding to movement toward (or away from) the net, and jumping. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac03a6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -6.65278625 -1.5\n",
      " -0.          0.          6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8bf3a7",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "The next code cell will run an untrained agent in the Environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f16b635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (max over agents) from episode 1: 0.0\n",
      "Score (max over agents) from episode 2: 0.0\n",
      "Score (max over agents) from episode 3: 0.0\n",
      "Score (max over agents) from episode 4: 0.09000000171363354\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 5):                                      # play game for 4 episodes\n",
    "    env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "    states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "    scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "    while True:\n",
    "        actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "        actions = np.clip(actions, -1, 1)    \n",
    "        env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "        next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "        rewards = env_info.rewards                         # get reward (for each agent)\n",
    "        dones = env_info.local_done                        # see if episode finished\n",
    "        scores += env_info.rewards                         # update the score (for each agent)\n",
    "        states = next_states                               # roll over states to next time step\n",
    "        if np.any(dones):                                  # exit loop if episode finished\n",
    "            break\n",
    "    print('Score (max over agents) from episode {}: {}'.format(i, np.max(scores)))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14f0a03",
   "metadata": {},
   "source": [
    "### 4. Train Multi Agent DDPG  to solve the environment\n",
    "\n",
    "The next code cell will train a Multiple DDPG Agents until it gets 100 consecutive episodes that have an average score of over 0.5. After that is done, it will save the model weights in local files(checkpoint_actor_0.pth,  checkpoint_actor_1.pth, checkpoint_critic_0.pth and checkpoint_critic_1.pth) to be used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2289ccc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tCurrent score: 0.00000\tAverage Score: 0.00100\n",
      "Episode 200\tCurrent score: 0.00000\tAverage Score: 0.00660\n",
      "Episode 300\tCurrent score: 0.10000\tAverage Score: 0.03490\n",
      "Episode 400\tCurrent score: 0.20000\tAverage Score: 0.09200\n",
      "Episode 500\tCurrent score: 0.10000\tAverage Score: 0.11990\n",
      "Episode 600\tCurrent score: 0.00000\tAverage Score: 0.07140\n",
      "Episode 700\tCurrent score: 0.09000\tAverage Score: 0.08870\n",
      "Episode 800\tCurrent score: 0.30000\tAverage Score: 0.11360\n",
      "Episode 900\tCurrent score: 0.00000\tAverage Score: 0.19870\n",
      "Episode 982\tCurrent score: 2.50000\tAverage Score: 0.51240\n",
      "Environment solved in 882 episodes!\tAverage Score: 0.51240\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def ddpg(n_episodes=2000, max_t=1000, print_every=100):\n",
    "    ma_controller = MultiAgentController(state_size=state_size, action_size=action_size, num_agents = num_agents, random_seed=71)\n",
    "    scores_window = deque(maxlen=print_every)\n",
    "    scores = []\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        states = env_info.vector_observations\n",
    "        ma_controller.reset()\n",
    "        score = np.zeros(num_agents)\n",
    "        for t in range(max_t):\n",
    "            actions = ma_controller.act(states)\n",
    "            \n",
    "            env_info = env.step(actions)[brain_name]   \n",
    "            next_states = env_info.vector_observations\n",
    "            rewards = env_info.rewards\n",
    "            dones = env_info.local_done\n",
    "            \n",
    "            ma_controller.step(states, actions, rewards, next_states, dones)\n",
    "            states = next_states\n",
    "            score += rewards\n",
    "            if np.any(dones):\n",
    "                break \n",
    "        \n",
    "        scores_window.append(np.max(score))\n",
    "        scores.append(np.max(score))\n",
    "        \n",
    "        print('\\rEpisode {}\\tCurrent score: {:.5f}\\tAverage Score: {:.5f}'.format(i_episode, np.max(score), np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % print_every == 0:\n",
    "            print('\\rEpisode {}\\tCurrent score: {:.5f}\\tAverage Score: {:.5f}'.format(i_episode, np.max(score), np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>=0.5:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.5f}'.format(i_episode-print_every, np.mean(scores_window)))\n",
    "            ma_controller.save()\n",
    "            break\n",
    "            \n",
    "    return scores\n",
    "\n",
    "scores = ddpg()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e95a483",
   "metadata": {},
   "source": [
    "### 5. Visualize the trained agent\n",
    "\n",
    "The next code cell will run the previously trained agent in the Environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43e0c5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: 2.1950000328943133\n",
      "Total score (averaged over agents) this episode: 0.0950000025331974\n",
      "Total score (averaged over agents) this episode: 0.5950000090524554\n",
      "Total score (averaged over agents) this episode: 0.1450000023469329\n"
     ]
    }
   ],
   "source": [
    "ma_controller = MultiAgentController(state_size=state_size, action_size=action_size, num_agents = num_agents, random_seed=71)\n",
    "\n",
    "# load the weights from file\n",
    "ma_controller.load()\n",
    "\n",
    "for t in range(1, 5):           \n",
    "    env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "    states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "    scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "    while True:\n",
    "        actions = ma_controller.act(states)                # select an action (for each agent)\n",
    "        env_info = env.step(actions)[brain_name]           # send all actions to the environment\n",
    "        next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "        rewards = env_info.rewards                         # get reward (for each agent)\n",
    "        dones = env_info.local_done                        # see if episode finished\n",
    "        scores += env_info.rewards                         # update the score (for each agent)\n",
    "        states = next_states                               # roll over states to next time step\n",
    "        if np.any(dones):                                  # exit loop if episode finished\n",
    "            break\n",
    "    print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5b85a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
